{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42597327-ffd2-4425-839b-981f4bd18e0a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "from scipy import fft\n",
    "from scipy import signal\n",
    "from scipy import optimize\n",
    "from scipy import stats\n",
    "import librosa.display as ld\n",
    "import librosa.feature as lf\n",
    "import librosa as lb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "palette = ['#000000', \n",
    "           '#ff0000', '#00ff00', '#0000ff', \n",
    "           '#00ffff', '#ff00ff', '#ffff00', \n",
    "           '#ff7777', '#77ff77', '#7777ff', \n",
    "           '#77ffff', '#ff77ff', '#ffff77', \n",
    "           '#ff7700', '#ff0077', '#77ff00',\n",
    "           '#00ff77', '#7700ff', '#0077ff',\n",
    "           '#007777', '#770077', '#777700',\n",
    "           '#777777']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438163b4-68ef-4583-84c6-634b085b9ece",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Finding Notes in Music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005eb91-c655-4ae1-9b58-d4e8ad63c008",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "What happens when we apply unsuperised learning to musical recordings? \n",
    "\n",
    "Can we find specific notes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2425db-da7e-46b3-885a-bd73f940f569",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d2fb30-52f3-4d29-81f9-a76558cc60a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### MusicNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b763c3e-ba09-444e-ac49-1fcb5c24fd90",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "https://www.kaggle.com/imsparsh/musicnet-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1cf97-aa3d-44b2-ae8c-ac7657b82d71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('musicnet_metadata.csv')\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53297c69-18d2-4127-8d58-fa6b41b0577f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_df['ensemble'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80c394-383a-430b-b744-2ca3f57c252d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "solos = [ens for ens in list(meta_df['ensemble'].unique()) if 'Solo' in ens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6e437-4e4a-4484-bca6-40e1f6e5af75",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mn_instruments_df = meta_df[meta_df['ensemble'].isin(solos)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced20fa-af63-4456-8044-e2c20ddacb6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mn_instruments_df.groupby(by='ensemble').count()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1adc146-3593-45fe-9ea1-d232baec2075",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "I want more than 4 instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db9401-f937-4c78-949a-b2f818562f14",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mn_instruments_df['ensemble'] = mn_instruments_df['ensemble'].apply(lambda x: x.split('Solo ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40de96e0-d3cc-4abc-baef-4b55386b7635",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mn_instruments_df.rename(columns={'ensemble':'instrument'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59dc4fa-aa6d-48ef-ad0e-334e0417596b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mn_instruments_df['file_path'] = mn_instruments_df['id'].apply(lambda i: f'musicnet/{i}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1156d-62e2-4b1a-9819-29fd8ad5c183",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cello_df = mn_instruments_df[mn_instruments_df['instrument'] == 'Cello'].copy()\n",
    "flute_df = mn_instruments_df[mn_instruments_df['instrument'] == 'Flute'].copy()\n",
    "piano_df = mn_instruments_df[mn_instruments_df['instrument'] == 'Piano'].copy()\n",
    "violin_df = mn_instruments_df[mn_instruments_df['instrument'] == 'Violin'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf8859-1f0a-4208-8000-4c4bfb937b8f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfpv_df = pd.concat([cello_df.sample(n=3), flute_df.sample(n=3), piano_df.sample(n=3), violin_df.sample(n=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a312e-56f6-4b2c-b784-881238e6016b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### URMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925d7114-68d9-4e3a-91a8-3e8870b006f7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "http://www2.ece.rochester.edu/projects/air/projects/URMP.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc6b0d-831f-4650-92e6-0ae06e149c5a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins_abbrev = {\n",
    "    'vn':'Violin',\n",
    "    'va':'Viola',\n",
    "    'vc':'Cello',\n",
    "    'db':'Double Bass',\n",
    "    'fl':'Flute',\n",
    "    'ob':'Oboe',\n",
    "    'cl':'Clarinet',\n",
    "    'sax':'Saxophone',\n",
    "    'bn':'Bassoon',\n",
    "    'tpt':'Trumpet',\n",
    "    'hn':'Horn',\n",
    "    'tbn':'Trombone',\n",
    "    'tba':'Tuba'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0bccb-d1ab-4f6d-befd-4edbd2ebfd2e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls = !ls urmp/Dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380b532-aed8-4e09-90ce-42c83c34027c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls.remove('Supplementary_Files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28fd3c-26d7-4128-aaec-405d108574a3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path_list = []\n",
    "for directory in ls:\n",
    "    files = !ls urmp/Dataset/{directory}\n",
    "    for f in files:\n",
    "        if '.wav' in f:\n",
    "            file_path_list.append(f'urmp/Dataset/{directory}/{f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b9f3f-869d-425b-aaff-ecc7db29d9c4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ins(file_path):\n",
    "    return file_path.split('/')[-1].split('_')[2]\n",
    "ins_list = [f for f in file_path_list if get_ins(f) in ins_abbrev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d765e0a-0b1a-4e9c-96b0-5922525ec21a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urmp_df = pd.DataFrame()\n",
    "urmp_df['file_path'] = ins_list\n",
    "urmp_df['instrument'] = list(map(get_ins, ins_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a60056-db95-4688-9bc6-9b8b0c7d19bf",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urmp_df.replace(ins_abbrev, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22149a4-09c6-4f60-8a28-e8fb0d0c777d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urmp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0538d73f-af6b-42b0-bd73-d9023ebc0101",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "urmp_df.groupby(by='instrument').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ba768-0389-4907-82c5-8540d7d59a9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe454e3f-de05-41b8-a655-3996f6b597c5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "URMP (13 instruments) + MusicNet (4 instuments) - overlap (3 instruments) = unique (14 instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e60bc-d08b-452b-9dbd-ae417596119e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_list = []\n",
    "for i in list(urmp_df['instrument'].unique()):\n",
    "    i_df = urmp_df[urmp_df['instrument'] == i].copy()\n",
    "    sample_list.append(i_df.sample(n=3))\n",
    "sample_list.append(piano_df[['file_path','instrument']].sample(n=3))\n",
    "equal_df = pd.concat(sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfc517-4ea0-4fed-a3d7-c70a72049c7e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "equal_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56da1dfe-1e47-4876-91c4-8acbe4debdd2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "equal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7499cd0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_dimension(X, algo, params, show_title=None, xlab=None, ylab=None):\n",
    "    font_size = 12\n",
    "    results = algo(**params).fit_transform(X)\n",
    "    x_label = f'{algo.__name__}_1'\n",
    "    y_label = f'{algo.__name__}_2'\n",
    "    res_df = pd.DataFrame(results, columns=[x_label, y_label])\n",
    "    splot = sns.scatterplot(data=res_df, x=x_label, y=y_label)\n",
    "    if xlab:\n",
    "        #splot.set(xlabel=xlab)\n",
    "        plt.xlabel(xlab, size=font_size)\n",
    "    else:\n",
    "        splot.set(xlabel='')\n",
    "    if ylab:\n",
    "        #splot.set(ylabel=ylab)\n",
    "        plt.ylabel(ylab, size=font_size)\n",
    "    else:\n",
    "        splot.set(ylabel='')\n",
    "    if show_title == 'auto':\n",
    "        title_elements = [f'{par[:min(6,len(par))]}:{str(val)[:min(6,len(par))]}' for par, val in params.items()]\n",
    "        title = ', '.join(title_elements)\n",
    "        _ = plt.title(title, size=font_size)\n",
    "    elif show_title:\n",
    "        _ = plt.title(show_title, size=font_size)\n",
    "    splot.tick_params(axis='both', which='both', left=False, right=False, bottom=False, top=False, labelbottom=False, labelleft=False)\n",
    "    return res_df\n",
    "    \n",
    "def parameter_grid(X, algo, params):\n",
    "    scaling = 3\n",
    "    all_keys = params.keys()\n",
    "    grid_keys = [key for key in all_keys if isinstance(params[key], list) and len(params[key]) > 1]\n",
    "    extra_keys = []\n",
    "    if len(grid_keys) > 2:\n",
    "        print(f'Got {len(grid_keys)} parameters with more that one value, I can only handle 2.')\n",
    "        return\n",
    "    elif len(grid_keys) == 2: # 2D case\n",
    "        key1, key2 = grid_keys\n",
    "        if len(all_keys) > len(grid_keys):\n",
    "            extra_keys = [key for key in all_keys if key not in grid_keys]\n",
    "    elif len(grid_keys) == 1: # 1D case\n",
    "        key1 = grid_keys[0]\n",
    "        if len(all_keys) > len(grid_keys):\n",
    "            single_keys = [key for key in all_keys if key not in grid_keys]\n",
    "            key2 = single_keys[0]\n",
    "            extra_keys = [key for key in single_keys if key != key2]\n",
    "        else: # 1D case\n",
    "            pars1 = params[key1]\n",
    "            width = len(pars1)\n",
    "            height = 1\n",
    "            plt.figure(figsize=(scaling*width, scaling*height))\n",
    "            for i, par1 in enumerate(pars1):\n",
    "                plt.subplot(height, width, i+1)\n",
    "                pars = {key1:par1}\n",
    "                x_label = f'{key1}:{par1}'\n",
    "                y_label = ''\n",
    "                _ = reduce_dimension(X, algo, pars, show_title=x_label, ylab=y_label)\n",
    "            plt.tight_layout()\n",
    "            return\n",
    "    else: # 0D case\n",
    "        _ = reduce_dimension(X, algo, params)\n",
    "        return\n",
    "    # 2D case\n",
    "    pars1 = params[key1]\n",
    "    pars2 = params[key2]\n",
    "    width = len(pars1)\n",
    "    height = len(pars2)\n",
    "    plt.figure(figsize=(scaling*width, scaling*height))\n",
    "    for i1, par1 in enumerate(pars1):\n",
    "        for i2, par2 in enumerate(pars2):\n",
    "            i = i1 + width*i2\n",
    "            plt.subplot(height, width, i+1)\n",
    "            extra_pars = {key:params[key] for key in extra_keys}\n",
    "            pars = {**{key1:par1, key2:par2}, **extra_pars}\n",
    "            if i1 == 0:\n",
    "                y_label = f'{key2}:{par2}'\n",
    "            else:\n",
    "                y_label = ''\n",
    "            if i2 == 0:\n",
    "                x_label = f'{key1}:{par1}'\n",
    "            else:\n",
    "                x_label = ''\n",
    "            _ = reduce_dimension(X, algo, pars, show_title=x_label, ylab=y_label, xlab='')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ebdc3-951c-413c-9c21-5604562cccc7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Single Recording Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c81e60-e002-4af8-a8a1-4ccfbb7a4ba6",
   "metadata": {},
   "source": [
    "1. Fourier Transform\n",
    "2. Dimensionality Reduction\n",
    "3. Cluster\n",
    "4. Identify Clusters\n",
    "5. Identify Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80365f-39f1-4cc6-8fcb-157b4b6113c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 1. Get the Fourier transforms of short samples of an audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead889ca-e11e-4cb9-8a4b-74a0301386c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16,5))\n",
    "x = np.linspace(0, 2*math.pi, 100)\n",
    "y1 = np.sin(x)\n",
    "y2 = 1/2*np.sin(2*x)\n",
    "y3 = 1/3*np.sin(3*x)\n",
    "_ = plt.subplot(1, 2, 1)\n",
    "_ = plt.plot(x, y1+y2+y3)\n",
    "_ = plt.subplot(1, 2, 2)\n",
    "_ = plt.plot(x, y1)\n",
    "_ = plt.plot(x, y2)\n",
    "_ = plt.plot(x, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04011e-4500-4da0-aa3f-384cba4683fd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def amp_sr_stfts(file_path): # sub_size is amp sample size for each fft, smaller means better time res, lower frequency res, and vice versa\n",
    "    sr, amp = wavfile.read(file_path) # read in audio file\n",
    "    if sr < 44000:\n",
    "        subs = 2048\n",
    "    else:\n",
    "        subs = 4096\n",
    "    stft_results = lb.stft(y=amp.astype(float), n_fft=subs, hop_length=subs//2) # get the Fourier transforms, no overlap between subsamples\n",
    "    ft = np.abs(stft_results.transpose()) # take the magnitude and transpose\n",
    "    ft /= ft.sum(axis=0, keepdims=True) # normalize amplitude in frequency domain by integral\n",
    "    return amp, sr, subs, ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b87d0b-a83a-4406-9d05-c2f237e2cfe5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "amp, sr, sub_size, ft = amp_sr_stfts('urmp/Dataset/35_Rondeau_vn_vn_va_db/AuSep_1_vn_35_Rondeau.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f94424-711e-45a8-b2f7-7c479559d6ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084737f0-3dc0-42a0-8688-f3156304b9b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aec768-f623-426f-8ea4-ad5ac1625b1d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "nonzero_fts = np.nonzero(ft.sum(axis=1))[0]\n",
    "nz_fts = ft[nonzero_fts]\n",
    "fts_normalized = nz_fts / nz_fts.sum(axis=1, keepdims=True)\n",
    "pca = PCA(n_components=2)\n",
    "pca_xy = pca.fit_transform(fts_normalized)\n",
    "pca_df = pd.DataFrame(pca_xy, columns=['pc1', 'pc2'])\n",
    "_ = sns.scatterplot(data=pca_df, x='pc1', y='pc2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725d5b7-1649-475b-8262-784b3e3bf522",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "There's not much we can do with this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864f314-63e0-4520-8aa6-2611c3a45056",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea5938-4101-456a-8fa1-92b67fd7aa47",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "parameter_grid(ft, TSNE, {'n_components':[2], 'perplexity':[5, 20, 50], 'n_iter':300})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51f7ef-59f7-4c11-9f4c-2321a80d860c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b37393-b280-4c4a-ac4a-b3ee15e2d644",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "parameter_grid(ft, UMAP, {'n_neighbors':[5, 15, 45], 'min_dist':[0.01, 0.1, 1.0], 'metric':'correlation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4011e8a-1911-43b0-8e07-6856fdc251b5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameter_grid(ft, UMAP, {'n_neighbors':[5, 10, 20], 'min_dist':[0.005, 0.01, 0.02], 'metric':'correlation'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76057f01-023d-4695-9ead-6de21e751925",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "smaller n_neighbors allows for finer differentiation, and smaller min_dist of keeps clusters tight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708d406-d4ee-4746-bc90-a89fdda40c70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "parameter_grid(ft, UMAP, {'n_neighbors':[5, 10], 'min_dist':[0.005, 0.01], 'metric':'correlation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c970565-da24-498c-b4f1-7774f76bbfff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "parameter_grid(ft, UMAP, {'n_neighbors':[5], 'min_dist':0.005, 'metric':['correlation', 'manhattan', 'euclidean', 'cosine']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911e3fd-76b2-4ac7-b4cb-097e3ba7b003",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = plt.figure(figsize=(10,8))\n",
    "umap_df = reduce_dimension(ft, UMAP, {'n_neighbors':5, 'min_dist':0.005, 'metric':'correlation'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0773e87-8996-4221-b122-f74d95643278",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 3. Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d83dc-f1e2-4d49-bb51-1310839b9145",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cluster_2D(df, algo, params, show_plot=False):\n",
    "    clusterer = algo(**params) # identify clusters in the UMAP results with DBSCAN\n",
    "    clusters = clusterer.fit_predict(df)\n",
    "    n_clusters = len(np.unique(clusters))\n",
    "    cols = df.columns.to_list()\n",
    "    if show_plot:\n",
    "        splot = sns.scatterplot(data=df, x=cols[0], y=cols[1], hue=clusters.astype(str), palette=sns.color_palette(palette[:n_clusters], n_clusters)) # plot the clusters and color them\n",
    "        splot.legend(bbox_to_anchor=(1.2, 1))\n",
    "    clustered_df = df.copy()\n",
    "    clustered_df['cluster'] = clusters\n",
    "    return clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83303a0b-61b0-4fb9-8f17-86e0e772434e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10,7))\n",
    "umap_dbscan_df = cluster_2D(umap_df, DBSCAN, {'eps':0.6, 'min_samples':7}, show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a3cfc-b6e7-4ac2-b981-4a164e366061",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "The groups are well-separated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97697c35-69c6-4020-957a-b0b76b25be51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 4. Identify Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47d7b7-68be-4f47-bf36-a4be320a5d2a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "First, I collect the audio sub-samples associated with each cluster and make them playable as a manual check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675576b-9d8d-4511-9f34-3697830e14a6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "times = lb.frames_to_samples(np.arange(ft.shape[0]), hop_length=sub_size//2) # get the start time index for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8bc2d-0a8e-47d1-a228-8ab18141c5ba",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "umap_dbscan_df['i_times'] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd0db8-2d0f-4bd3-833f-f8b674673d7a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def collect_samps(amp, groups_df, group_num): # for a given cluster, return the start and end time indices for all samples in that cluster\n",
    "    this_group_intervals = []\n",
    "    interval = []\n",
    "    group_times = groups_df[groups_df['cluster'] == group_num]['i_times']\n",
    "    for i in group_times:\n",
    "        if not interval:\n",
    "            interval = [i, i]\n",
    "        sub_interval = [i, i+sub_size]\n",
    "        if sub_interval[0] <= interval[1]:\n",
    "            interval[1] = sub_interval[1]\n",
    "            if sub_interval[0] == group_times.iloc[-1]:\n",
    "                interval[1] = min(len(amp)-1, interval[1])\n",
    "                this_group_intervals.append(interval)\n",
    "        else:\n",
    "            this_group_intervals.append(interval)\n",
    "            interval = sub_interval\n",
    "    return this_group_intervals\n",
    "\n",
    "group_intervals = {} # fill a dictionary with cluster numbers and their corresponding sample start and end time indices\n",
    "for g in umap_dbscan_df['cluster']:\n",
    "    group_intervals[g] = collect_samps(amp, umap_dbscan_df, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00788797-a1e5-4a26-ab8b-a18432987582",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_amps = {}\n",
    "for g in group_intervals: # combine all of the samples for each cluster and make the clusters playable.\n",
    "    group_amp = np.array([])\n",
    "    for i in group_intervals[g]:\n",
    "        group_amp = np.append(group_amp, amp[i[0]:i[1]])\n",
    "    if len(group_amp) >= sr:\n",
    "        group_amps[g] = group_amp\n",
    "        print(g)\n",
    "        Audio(group_amp, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a168d9db-cf79-43cb-b33a-1f1f2f8266e3",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Each group typically corresponds to a single note, sometimes with an half-step, 5th, or octave above or below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b384ac-ef93-4a33-8c4d-4a82807abad2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for g in [0, 1, 8, 11]:\n",
    "    group_amp = group_amps[g]\n",
    "    print(g)\n",
    "    Audio(group_amp, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a929aad-b73b-492d-996a-ab54ac83f3ef",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_indices(list_in):\n",
    "    list_max = max(list_in)\n",
    "    return [i for i, val in enumerate(list_in) if val == list_max]\n",
    "\n",
    "def peak_freq_diffs(freq, peaks):\n",
    "    return freq[peaks[1:]] - freq[peaks[:-1]]\n",
    "\n",
    "def fundamental_freqs(clusters_to_fit, cluster_intervals, amp, sr, show_plot=False):\n",
    "    cluster_hrfts = {}\n",
    "    cluster_peaks = {}\n",
    "    cluster_peak_seps = {}\n",
    "    cluster_fundamentals = {}\n",
    "    n_clusters = len(clusters_to_fit)\n",
    "    n_rows = n_clusters//2 + n_clusters % 2\n",
    "    if show_plot:\n",
    "        _ = plt.figure(figsize=(20, 5*n_rows))\n",
    "    for i, c in enumerate(clusters_to_fit): # loop over clusters that are playable for at least 1 second\n",
    "        intervals = cluster_intervals[c] # get the interval indices for this cluster\n",
    "        interval_lengths = [i[1] - i[0] for i in intervals] # convert to interval lengths\n",
    "        max_i = max_indices(interval_lengths) # get the indices of all maximum length intervals\n",
    "        max_length_samples = [amp[intervals[i][0]:intervals[i][1]] for i in max_i] # get the max length interval sample(s)\n",
    "        fts = [abs(fft.rfft(sample)) for sample in max_length_samples] # get the Fourier transform(s) of max length sample(s)\n",
    "        fts_normalized = [ft_raw/ft_raw.sum(axis=0, keepdims=True) for ft_raw in fts] # normalize the Fourier transform(s)\n",
    "        avg_fts = sum(fts_normalized)/len(fts_normalized) # get the average normalized Fourier transform\n",
    "        hrft = avg_fts/avg_fts.sum() # normalize again, hrft = high-resolution Fourier transform\n",
    "        freq = lb.fft_frequencies(sr=sr, n_fft=len(max_length_samples[0]))\n",
    "        cluster_hrfts[c] = [freq, hrft]\n",
    "        freq_res = freq[1] - freq[0]\n",
    "        freq_dist = int(round(25 / freq_res)) # distance sets a lower limit on detectable frequencies\n",
    "        peaks, peak_properties = signal.find_peaks(hrft, distance=freq_dist, prominence=0.002)\n",
    "        if len(peaks) < 1:\n",
    "            continue\n",
    "        if freq[peaks][0] < 25:\n",
    "            peaks = peaks[1:]\n",
    "        multiples_flag = False\n",
    "        if len(peaks) > 1:\n",
    "            multiples_flag = True\n",
    "            seps = peak_freq_diffs(freq, peaks)\n",
    "            cluster_peak_seps[c] = seps\n",
    "            diff_ratio = seps.max() / seps.min()\n",
    "            if diff_ratio > 6:\n",
    "                freq_dist = int(round(2*seps.min() / freq_res))\n",
    "                peaks, peak_properties = signal.find_peaks(hrft, distance=freq_dist, prominence=0.002)\n",
    "                if freq[peaks][0] < freq_dist:\n",
    "                    peaks = peaks[1:]\n",
    "                    cluster_peak_seps[c] = peak_freq_diffs(freq, peaks)\n",
    "        plot_frac = 0.6\n",
    "        plot_end = int(plot_frac*len(freq))\n",
    "        if show_plot:\n",
    "            _ = plt.subplot(n_rows, 2, i+1)\n",
    "            _ = plt.plot(freq[:plot_end], hrft[:plot_end])\n",
    "            _ = plt.plot(freq[peaks], hrft[peaks], 'rx')\n",
    "        if multiples_flag:\n",
    "            peak_freqs = freq[peaks]\n",
    "            peak_heights = hrft[peaks]\n",
    "            i_max = peak_heights.argmax()\n",
    "            i_fund = i_max\n",
    "            freq_max = peak_freqs[i_max]\n",
    "            freq_fund = freq_max\n",
    "            for f in [1/3, 1/2]:\n",
    "                guess_freq = f*freq_max\n",
    "                for i in range(i_max):\n",
    "                    frac_error = abs(peak_freqs[i] - guess_freq)/guess_freq\n",
    "                    if frac_error < 0.04:\n",
    "                        i_fund = i\n",
    "                        freq_fund = peak_freqs[i]\n",
    "            matches = 0\n",
    "            for f in range(2,15):\n",
    "                harmonic = f*freq_fund\n",
    "                for p in range(i_fund+1, len(peaks)):\n",
    "                    frac_error = abs(harmonic - peak_freqs[p]) / harmonic\n",
    "                    if frac_error < 0.04:\n",
    "                        matches += 1\n",
    "                if show_plot:\n",
    "                    _ = plt.axvline(f*freq_fund, c='y')\n",
    "            if matches >= 1:\n",
    "                cluster_fundamentals[c] = freq_fund\n",
    "        if show_plot:\n",
    "            _ = plt.title(f'{c}')\n",
    "    if show_plot:\n",
    "        plt.tight_layout()\n",
    "    return cluster_fundamentals\n",
    "\n",
    "cluster_fundamental_freqs = fundamental_freqs(group_amps, group_intervals, amp, sr, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433604be-fb44-4aff-81f7-cd5767bb99cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "sample_cluster_amps = {c:group_amps[c] for c in [1, 5, 8, 11]}\n",
    "sample_cluster_intervals = {c:group_intervals[c] for c in [1, 5, 8, 11]}\n",
    "sample_fundamental_freqs = fundamental_freqs(sample_cluster_amps, sample_cluster_intervals, amp, sr, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93366cba-e939-4cfa-a9b7-06f9a840a9d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_fundamental_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e20bda-55e3-4a66-b1f4-e6b7ca061ecb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 5. Identify Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd9405-3b8f-4689-84b4-fb3093d1682c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fundamental(sample):\n",
    "    ft_raw = abs(fft.rfft(sample)) # get the Fourier transform of sample\n",
    "    ft = ft_raw/ft_raw.sum() # normalize the Fourier transform(s)\n",
    "    freq = lb.fft_frequencies(sr=sr, n_fft=len(sample))\n",
    "    freq_res = freq[1] - freq[0]\n",
    "    freq_dist = int(round(25 / freq_res)) # distance sets a lower limit on detectable frequencies (25 Hz)\n",
    "    peaks, peak_properties = signal.find_peaks(ft, distance=freq_dist, prominence=0.002)\n",
    "    if freq[peaks][0] < 25: # drop peaks less than 25 Hz\n",
    "        peaks = peaks[1:]\n",
    "    multiples_flag = False # we don't know if there are multiple peaks yet\n",
    "    if len(peaks) > 1:\n",
    "        multiples_flag = True # there are multiple peaks\n",
    "        seps = peak_freq_diffs(freq, peaks) # separation distances between the peaks\n",
    "        #cluster_peak_seps[g] = seps\n",
    "        diff_ratio = seps.max() / seps.min() # the ratio of the maximum separation to the minimum separation\n",
    "        if diff_ratio > 6: # if that ratio is greater than 6, we probably found too many little peaks\n",
    "            freq_dist = int(round(2*seps.min() / freq_res)) # calculate a new minimum distance between adjacent peaks\n",
    "            peaks, peak_properties = signal.find_peaks(ft, distance=freq_dist, prominence=0.002)\n",
    "            if freq[peaks][0] < freq_dist: # if the first peak is less than our new minimum separation\n",
    "                peaks = peaks[1:] # drop the first peak\n",
    "                #cluster_peak_seps[g] = peak_freq_diffs(freq, peaks)\n",
    "    if multiples_flag: # find the fundamental frequency if we fit more than one peak\n",
    "        peak_freqs = freq[peaks]\n",
    "        peak_heights = ft[peaks]\n",
    "        i_max = peak_heights.argmax() # the index of the tallest peak\n",
    "        i_fund = i_max # assume the tallest peak has the fundamental frequency for now\n",
    "        freq_max = peak_freqs[i_max]\n",
    "        freq_fund = freq_max\n",
    "        for f in [1/3, 1/2]: # check for peaks at 1/3 and 1/2 of the peak frequency in case the fundamental is not dominant\n",
    "            guess_freq = f*freq_max # guesses for the fundamental\n",
    "            for i in range(i_max): # for each peak before the dominant\n",
    "                frac_error = abs(peak_freqs[i] - guess_freq)/guess_freq # calculate the fractional error\n",
    "                if frac_error < 0.04: # if the fractional error is less than 4%\n",
    "                    i_fund = i # assume we found the actual fundamental\n",
    "                    freq_fund = peak_freqs[i]\n",
    "        matches = 0 # initialize a counter for the number of matches between harmonics and peaks\n",
    "        for f in range(2,15): # for each harmonic from 2x to 15x fundamental frequency\n",
    "            harmonic = f*freq_fund\n",
    "            for p in range(i_fund+1, len(peaks)): # for each peak after the fundamental\n",
    "                frac_error = abs(harmonic - peak_freqs[p]) / harmonic # calculate the fractional error\n",
    "                if frac_error < 0.04: # if the fractional error is less than 4%\n",
    "                    matches += 1 # assume a match\n",
    "        if matches >= 1: # if there was at least one match between harmonics and peaks\n",
    "            return freq_fund # return the fundamental frequency\n",
    "        else:\n",
    "            return 0.0 # 0.0 means we didn't find a convincing fundamental frequency\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947f3fa-faae-434b-9080-e70d0d31cf71",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_dim(X, algo, params):\n",
    "    results = algo(**params).fit_transform(X)\n",
    "    xlabel = f'{algo.__name__}_1'\n",
    "    ylabel = f'{algo.__name__}_2'\n",
    "    res_df = pd.DataFrame(results, columns=[xlabel, ylabel])\n",
    "    return res_df\n",
    "\n",
    "def get_cluster_intervals(amp, clustered_df, cluster_num, sub_size): # for a given cluster, return the start and end time indices for all samples in that cluster\n",
    "    this_cluster_intervals = []\n",
    "    cluster_length = 0\n",
    "    interval = []\n",
    "    cluster_times = clustered_df[clustered_df['cluster'] == cluster_num]['i_times']\n",
    "    for i in cluster_times:\n",
    "        if not interval: # get the first interval of the cluster\n",
    "            interval = [i, i] # give it zero length for now\n",
    "        sub_interval = [i, i+sub_size] # sub_interval is the sub_size-sized interval that will extend interval or start a new one\n",
    "        if sub_interval[0] <= interval[1]: # if the current sub_interval starts where or before the current interval ends\n",
    "            interval[1] = sub_interval[1] # extend the interval to the end of the current sub_interval\n",
    "            if sub_interval[0] == cluster_times.iloc[-1]: # if the current sub_interval is the last\n",
    "                interval[1] = min(len(amp)-1, interval[1]) # end the current interval at the end of the amp data if that comes first.\n",
    "                cluster_length += (interval[1] - interval[0])\n",
    "                this_cluster_intervals.append(interval) # add this interval to the list for this cluster\n",
    "        else:\n",
    "            cluster_length += (interval[1] - interval[0])\n",
    "            this_cluster_intervals.append(interval)\n",
    "            interval = sub_interval\n",
    "    return this_cluster_intervals, cluster_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e999197-ddce-4b5f-a517-f32a54318137",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_recording(file_path):\n",
    "    amp, sr, sub_size, ft = amp_sr_stfts(file_path)\n",
    "    umap_df = reduce_dim(ft, UMAP, {'n_neighbors':5, 'min_dist':0.005, 'metric':'correlation'}) # 3 parameters\n",
    "    umap_dbscan_df = cluster_2D(umap_df, DBSCAN, {'eps':0.6, 'min_samples':7}) # 2 more parameters\n",
    "    times = lb.frames_to_samples(np.arange(ft.shape[0]), hop_length=sub_size//2) # get the start time index for each sample\n",
    "    umap_dbscan_df['i_times'] = times\n",
    "    cluster_intervals = {} # fill a dictionary with cluster numbers and their corresponding sample start and end time indices\n",
    "    clusters_to_fit = []\n",
    "    for c in umap_dbscan_df['cluster'].unique():\n",
    "        cluster_intervals[c], cluster_length = get_cluster_intervals(amp, umap_dbscan_df, c, sub_size)\n",
    "        if cluster_length >= sr: # keep cluster if the total duration is at least 1 second\n",
    "            clusters_to_fit.append(c)\n",
    "    #print(f'{clusters_to_fit}, {cluster_intervals}')\n",
    "    return fundamental_freqs(clusters_to_fit, cluster_intervals, amp, sr), cluster_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187aaee8-31de-431e-bf86-8de33992217c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "frequencies, intervals = process_recording('urmp/Dataset/35_Rondeau_vn_vn_va_db/AuSep_1_vn_35_Rondeau.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92077779-f647-4a1b-a210-fffddf12b649",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pitch_plot(frequencies, intervals, file_path): # for frequency determined by cluster\n",
    "    sr, amp = wavfile.read(file_path)\n",
    "    recording_length = len(amp)\n",
    "    x = np.linspace(0, recording_length/sr, recording_length)\n",
    "    y = np.zeros(recording_length)\n",
    "    for c in frequencies:\n",
    "        for interval in intervals[c]:\n",
    "            y[interval[0]:interval[1]] = frequencies[c] * np.ones(interval[1] - interval[0])\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.scatter(x[:recording_length//6], y[:recording_length//6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fab73d-d954-43a8-92c8-240298bacaed",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pitch_plot_2(frequencies, intervals, file_path): # for frequency determined by interval\n",
    "    sr, amp = wavfile.read(file_path)\n",
    "    recording_length = len(amp)\n",
    "    x = np.linspace(0, recording_length/sr, recording_length)\n",
    "    y = np.zeros(recording_length)\n",
    "    all_intervals = [interval for interval_list in list(intervals.values()) for interval in interval_list]\n",
    "    clustered_intervals = [interval for interval_list in [intervals[c] for c in frequencies] for interval in interval_list]\n",
    "    for i in all_intervals:\n",
    "        fund = get_fundamental(amp[i[0]:i[1]])\n",
    "        if fund > 0.0:\n",
    "            y[i[0]:i[1]] = fund * np.ones(i[1] - i[0])\n",
    "        else:\n",
    "            if i in clustered_intervals:\n",
    "                for c in frequencies:\n",
    "                    if i in intervals[c]:\n",
    "                        y[i[0]:i[1]] = frequencies[c] * np.ones(i[1] - i[0])\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.scatter(x[:recording_length//6], y[:recording_length//6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2218f227-799d-4ef1-806e-b36e72f065e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pitch_plot(frequencies, intervals, 'urmp/Dataset/35_Rondeau_vn_vn_va_db/AuSep_1_vn_35_Rondeau.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d1dfb-712b-4380-bd67-062f8740b0dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pitch_plot_2(frequencies, intervals, 'urmp/Dataset/35_Rondeau_vn_vn_va_db/AuSep_1_vn_35_Rondeau.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0bd508-fe08-4c83-8875-537910ec4646",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sr, amp = wavfile.read('urmp/Dataset/35_Rondeau_vn_vn_va_db/AuSep_1_vn_35_Rondeau.wav')\n",
    "Audio(amp, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f24ea6-e618-4c21-bfc1-bdda2b88a96b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Collecting Notes by Instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55dd315-97f2-4399-bc63-854cd3b093e0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "ins_list = list(equal_df['instrument'].unique())\n",
    "for ins in ins_list:\n",
    "    file_list = equal_df[equal_df['instrument'] == ins]['file_path'].to_list()\n",
    "    for i, file_path in enumerate(file_list):\n",
    "        frequencies, intervals = process_recording(file_path)\n",
    "        results_dict[f'{ins}_{i}'] = {'frequencies':frequencies, 'intervals':intervals}\n",
    "    print(f'{ins} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67414e2d-4389-4b52-ab11-e48907102982",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0deab1-02d1-4a12-9a0f-b2bdbe5d5100",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "done_list = [key.split('_')[0] for key in list(results_dict.keys())]\n",
    "done_list = list(set(done_list))\n",
    "remainder_list = [item for item in ins_list if item not in done_list]\n",
    "\n",
    "file_list = equal_df[equal_df['instrument'] == 'Piano']['file_path'].to_list()\n",
    "for i, file_path in enumerate(file_list):\n",
    "    frequencies, intervals = process_recording(file_path)\n",
    "    results_dict[f'{ins}_{i}'] = {'frequencies':frequencies, 'intervals':intervals}\n",
    "print(f'{ins} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e65b2-48f3-43e2-88c4-390bc11db672",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3232b-15ff-4add-9e31-1156964337a0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "equal_df['key'] = list(results_dict.keys())\n",
    "equal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153499f3-0d5c-4a78-87e1-c8ddf7588195",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "a_file = open(\"results_dict.pkl\", \"wb\")\n",
    "pickle.dump(results_dict, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff557a6-ef31-4bad-81fc-1cc58b0a1e53",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "freqs_by_ins_dict = {}\n",
    "for ins in ins_list:\n",
    "    ins_df = equal_df[equal_df['instrument'] == ins]\n",
    "    ins_freqs = []\n",
    "    for key in ins_df['key']:\n",
    "        freqs = list(results_dict[key]['frequencies'].values())\n",
    "        ins_freqs.append(freqs)\n",
    "    ins_freqs = [f for f_list in ins_freqs for f in f_list]\n",
    "    freqs_by_ins_dict[ins] = list(set(ins_freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6354c9-388a-484e-a9d7-a17049c2c421",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins_freq_res = []\n",
    "for ins, freqs in freqs_by_ins_dict.items():\n",
    "    freqs.sort()\n",
    "    freq_diffs = [freqs[i+1] - freqs[i] for i in range(len(freqs)-1)]\n",
    "    freq_res = min([diff for diff in freq_diffs if diff > 0.001])\n",
    "    ins_freq_res.append(freq_res)\n",
    "freq_res = min(ins_freq_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22990400-a85e-46f2-bffe-9dc07edefe32",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "freqs_flat = list(set([freq for sublist in list(freqs_by_ins_dict.values()) for freq in sublist]))\n",
    "freqs_flat.sort()\n",
    "freq_min = freqs_flat[0]\n",
    "freq_max = freqs_flat[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a447aa6c-3e5c-4ffc-adee-9e76f3aa8c8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "pitches_df = pd.DataFrame()\n",
    "freq_range = freq_max - freq_min\n",
    "arb_freq_res = 1.0\n",
    "n_bins = int(freq_range // arb_freq_res) + 1\n",
    "bins = np.linspace(freq_min-arb_freq_res, freq_max+arb_freq_res, n_bins+1)\n",
    "for ins, freqs in freqs_by_ins_dict.items():\n",
    "    fill = np.zeros(n_bins)\n",
    "    inds = np.digitize(freqs, bins)\n",
    "    for i in inds:\n",
    "        fill[i-1] += 1\n",
    "    pitches_df[ins] = fill\n",
    "_ = plt.figure(figsize=(12,10))\n",
    "_ = sns.heatmap(pitches_df)\n",
    "hide_code_in_slideshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc72cd-8e6b-4d31-8c66-de5f34cbdf14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d44cfe-b3ea-425e-81c1-ab05c386e096",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc79f30-76be-45ce-9cb1-06687e8bd0e9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Data processing outline:\n",
    "\n",
    "1. Select solo instrument recordings\n",
    "2. For each recording:\n",
    "\n",
    "    a. Do short-time Fourier transforms\n",
    "    \n",
    "    b. Apply UMAP\n",
    "    \n",
    "    c. Apply DBSCAN to UMAP results, this defines the clusters\n",
    "    \n",
    "    d. For each cluster:\n",
    "        i. Take the longest sample (average) FT\n",
    "        ii. Find the most prominent peaks at least 25 Hz apart\n",
    "        iii. Find the dominant frequency, check for peaks at 1/2 and 1/3 of this frequency\n",
    "        iv. Identify the fundamental frequency (lowest peak frequency within 4% of these three (dom, 1/2 dom, 1/3 dom)\n",
    "        v. Count the number of peaks within 4% of the harmonics of the fundamental frequency\n",
    "        vi. If there is at least 1 peak matching a harmonic, save that fundamental frequency for that cluster\n",
    "    \n",
    "    e. Return the fundamental frequency for each cluster or interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149a922-7ce1-49a0-8ba1-05c0563d6aac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "# Failed Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612a040-b74a-49b9-a8b9-ee55b1e0a4ba",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# freq = lb.fft_frequencies(sr=sr, n_fft=sub_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668833e2-36ec-4bc1-9b5a-e543e9ad0460",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_cluster_ffts(ft, freq, clustered_df, cluster_num):\n",
    "#     fts_0 = ft[np.where(clustered_df['cluster']==cluster_num)]\n",
    "#     for ft_0 in fts_0:\n",
    "#         _ = plt.plot(freq, ft_0, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671433d4-9ff8-408b-a4d1-68ffa3d467f2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_cluster_avg_fft(ft, freq, clustered_df, cluster_num):\n",
    "#     avg_ft_0 = cluster_avg_fft(ft, freq, clustered_df, cluster_num)\n",
    "#     _ = plt.plot(freq, avg_ft_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606282d3-b2e8-4a02-8b03-e988b9b8e765",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for c in cluster_peaks:\n",
    "#    peaks = cluster_peaks[c]\n",
    "#    freq, hrft = cluster_hrfts[c]\n",
    "#    peak_heights = hrft[peaks]\n",
    "#    peak_freqs = freq[peaks]\n",
    "#    if peak_heights[0] = max(peak_heights):\n",
    "#        # take multiples\n",
    "#        for i in range(1, len(peaks)):\n",
    "#            ratio = peak_freqs[i]/peak_freqs[0]\n",
    "#            abs_error = abs(ratio-round(ratio))/round(ratio)\n",
    "#            if abs_error < 0.1:\n",
    "#                print(rounded_frac)\n",
    "#    else:\n",
    "#        # take fractions and multiples        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d318f370-5cd7-4097-afa3-6f493b1dc4f5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for c in cluster_peak_seps:\n",
    "#    seps = cluster_peak_seps[c]\n",
    "#    print(c)\n",
    "#    s_max = max(seps)\n",
    "#    for s in seps:\n",
    "#        s_ratio = s_max/s\n",
    "#        if s_ratio > 1.5:\n",
    "#            round_abs_diff = abs(round(s_ratio) - s_ratio)\n",
    "#            if round_abs_diff < 0.05:\n",
    "#                print(f's_ratio: {s_ratio}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301af09-9be0-4769-b5ac-460bbaedc4cc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#n_clusters = umap_dbscan_df['cluster'].nunique()\n",
    "#_ = plt.figure(figsize=(20, 5*(n_clusters//2 + n_clusters % 2)))\n",
    "#for i in umap_dbscan_df['cluster'].unique():\n",
    "#    i_plot = i + 1 if i > -1 else n_clusters\n",
    "#    _ = plt.subplot(n_clusters//2 + n_clusters % 2, 2, i_plot)\n",
    "#    plot_cluster_ffts(ft, freq, umap_dbscan_df, i)\n",
    "#    _ = plt.title(f'{i}')\n",
    "#_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05c418-17b6-4b15-8071-726c3bca8b33",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#_ = plt.figure(figsize=(16,7))\n",
    "#for i, c in enumerate([0, 11, 1, 5]):\n",
    "#    _ = plt.subplot(2, 2, i+1)\n",
    "#    plot_cluster_ffts(ft, freq, umap_dbscan_df, c)\n",
    "#    _ = plt.title(f'{c}')\n",
    "#_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832cb943-fd96-4a05-aed2-0f1bf613d2ad",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# equal_tempered_pitches = [27.5*2**(i/12) for i in range(88)]\n",
    "# note_pitches = equal_tempered_pitches\n",
    "# notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "# note_names = ['A0', 'A#0', 'B0'] + [f'{note}{i}' for i in range(1, 8) for note in notes] + ['C8']\n",
    "# notes_df = pd.DataFrame()\n",
    "# notes_df['name'] = note_names\n",
    "# notes_df['pitch'] = note_pitches\n",
    "# notes_df['lower_pitch'] = list(map(lambda x: x / 1.01, note_pitches))\n",
    "# notes_df['upper_pitch'] = list(map(lambda x: x * 1.01, note_pitches))\n",
    "\n",
    "# def cluster_note(ft, freqs, clustered_df, cluster_num):\n",
    "#     caf = cluster_avg_fft(ft, freqs, clustered_df, cluster_num)\n",
    "#     peaks = prominent_peaks(caf)\n",
    "#     if len(peaks) < 2: # If there aren't enough prominent peaks, assume a rest in the music.\n",
    "#         return 'rest'\n",
    "#     diffs = peak_freq_diffs(freqs, peaks)\n",
    "#     cm = centralize(diffs).mean()\n",
    "#     return find_note(cm, notes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c540fb6-8c91-4c04-831d-d74c086336a7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def cluster_avg_fft(ft, freq, clustered_df, cluster_num): # return the average Fourier Transform of a cluster\n",
    "#     fts_0 = ft[np.where(clustered_df['cluster']==cluster_num)]\n",
    "#     return fts_0.mean(axis=0)\n",
    "\n",
    "# def prominent_peaks(caf):\n",
    "#     peaks, peak_properties = signal.find_peaks(caf, prominence=0.002)\n",
    "#     return peaks\n",
    "\n",
    "# def centralize(a, sigmas=1):\n",
    "#     upper = a.mean() + sigmas*a.std()\n",
    "#     lower = a.mean() - sigmas*a.std()\n",
    "#     a_below = a[a <= upper]\n",
    "#     a_central = a_below[a_below >= lower]\n",
    "#     return a_central\n",
    "\n",
    "# def find_note(freq, note_df):\n",
    "#     if note_df['lower_pitch'].iloc[0] <= freq <= note_df['upper_pitch'].iloc[-1]: # check if freq is in overall range of notes\n",
    "#         for i, row in note_df.iterrows():\n",
    "#             if row['lower_pitch'] <= freq <= row['upper_pitch']:\n",
    "#                 return row['name']\n",
    "#     return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7991ff",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cluster_central_freqs = {}\n",
    "# cluster_diffs_central = {}\n",
    "# _ = plt.figure(figsize=(20,20))\n",
    "# for i, c in enumerate(cluster_peak_seps):\n",
    "#     diffs = cluster_peak_seps[c]\n",
    "#     _ = plt.subplot(len(cluster_peak_seps) // 2 + len(cluster_peak_seps) % 2, 2, i+1)\n",
    "#     _ = plt.title(f'{c}')\n",
    "#     _ = sns.histplot(diffs, bins=20, kde=True)\n",
    "#     _ = plt.axvline(diffs.mean(), c='g')\n",
    "#     upper = diffs.mean() + diffs.std()\n",
    "#     _ = plt.axvline(upper, c='r')\n",
    "#     lower = diffs.mean() - diffs.std()\n",
    "#     _ = plt.axvline(lower, c='r')\n",
    "#     diffs_central = centralize(diffs)\n",
    "#     cluster_diffs_central[c] = diffs_central\n",
    "#     diffs_central_mean = diffs_central.mean()\n",
    "#     _ = plt.axvline(diffs_central_mean, c='k')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283196b-6ad6-4e6d-9859-b1701848d612",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#n_clusters = umap_dbscan_df['cluster'].nunique()\n",
    "#cluster_avg_fft_peaks = {}\n",
    "#cluster_diffs = {}\n",
    "#_ = plt.figure(figsize=(20, 5*(n_clusters//2 + n_clusters % 2)))\n",
    "#for i in umap_dbscan_df['cluster'].unique():\n",
    "#    i_plot = i + 1 if i > -1 else n_clusters\n",
    "#    caf = cluster_avg_fft(ft, freq, umap_dbscan_df, i)\n",
    "#    peaks, peak_properties = signal.find_peaks(caf, prominence=0.0008)\n",
    "#    if len(peaks) > 1:\n",
    "#        cluster_diffs[i] = peak_freq_diffs(freq, peaks)\n",
    "#    _ = plt.subplot(n_clusters//2 + n_clusters % 2, 2, i_plot)\n",
    "#    _ = plt.plot(freq, caf)\n",
    "#    _ = plt.plot(freq[peaks], caf[peaks], 'rx')\n",
    "#    _ = plt.title(f'{i}')\n",
    "#_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6adb7ac-86da-4da2-9e1c-f7d21e990c28",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#_ = plt.figure(figsize=(16,7))\n",
    "#for i, c in enumerate([0, 11, 1, 5]):\n",
    "#    caf = cluster_avg_fft(ft, freq, umap_dbscan_df, c)\n",
    "#    peaks, peak_properties = signal.find_peaks(caf, prominence=0.0008)\n",
    "#    if len(peaks) > 1:\n",
    "#        cluster_diffs[i] = peak_freq_diffs(freq, peaks)\n",
    "#    _ = plt.subplot(2, 2, i+1)\n",
    "#    _ = plt.plot(freq, caf)\n",
    "#    _ = plt.plot(freq[peaks], caf[peaks], 'rx')\n",
    "#    _ = plt.title(f'{i}')\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e56383-8ab2-46dc-b834-15d708e77253",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#_ = plt.figure(figsize=(16,4))\n",
    "#for i, c in enumerate([1, 5]):\n",
    "#    diffs = cluster_diffs[c]\n",
    "#    _ = plt.subplot(1, 2, i+1)\n",
    "#    _ = plt.title(f'{c}')\n",
    "#    _ = sns.histplot(diffs)\n",
    "#     _ = plt.axvline(diffs.mean(), c='g')\n",
    "#     upper = diffs.mean() + diffs.std()\n",
    "#     _ = plt.axvline(upper, c='r')\n",
    "#     lower = diffs.mean() - diffs.std()\n",
    "#     _ = plt.axvline(lower, c='r')\n",
    "#     diffs_central = centralize(diffs)\n",
    "#     cluster_diffs_central[c] = diffs_central\n",
    "#     diffs_central_mean = diffs_central.mean()\n",
    "#     diffs_central_central_mean = centralize(diffs_central).mean()\n",
    "#     cluster_central_freqs[c] = diffs_central_mean\n",
    "#     _ = plt.axvline(diffs_central_mean, c='k')\n",
    "#     _ = plt.axvline(diffs_central_central_mean, c='m')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584869dc-6f27-4f0a-bc8b-52115aaadfec",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def remove_outliers(a):\n",
    "#    mode_info = stats.mode(a)\n",
    "#    if mode_info[1] > 2:\n",
    "#        reference = mode_info[0]\n",
    "#    else:\n",
    "#        reference = a.mean()\n",
    "#    factor = 1.5\n",
    "#    lower = reference / factor\n",
    "#    upper = reference * factor\n",
    "#    return a[(a > lower) & (a < upper)]\n",
    "\n",
    "#_ = plt.figure(figsize=(20,40))\n",
    "#for i, c in enumerate(cluster_diffs):\n",
    "#    diffs = cluster_diffs[c]\n",
    "#    mode_info = stats.mode(diffs)\n",
    "#    mode = mode_info[0]\n",
    "#    mean = diffs.mean()\n",
    "#    _ = plt.subplot(21, 2, i+1)\n",
    "#    _ = plt.plot(diffs)\n",
    "#    _ = plt.axhline(mode, c='r')\n",
    "#    _ = plt.axhline(mean, c='g')\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc51e6-a423-4894-836d-88754df8229d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#_ = plt.figure(figsize=(20,40))\n",
    "#for i, c in enumerate(cluster_diffs):\n",
    "#    inliers = remove_outliers(cluster_diffs[c])\n",
    "#    _ = plt.subplot(21, 2, i+1)\n",
    "#    _ = plt.plot(inliers)\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f1cc1-a4c9-4b5e-8d72-122fd4ae0376",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#_ = plt.figure(figsize=(20,10))\n",
    "#for i, c in enumerate(cluster_diffs_central):\n",
    "#    central_diffs = cluster_diffs_central[c]\n",
    "#    _ = plt.subplot(len(cluster_diffs_central) // 2 + len(cluster_diffs_central) % 2, 2, i+1)\n",
    "#    _ = sns.histplot(central_diffs)\n",
    "#    _ = plt.axvline(central_diffs.mean(), c='g')\n",
    "#    sigmas = 1.5\n",
    "#    upper = central_diffs.mean() + sigmas*central_diffs.std()\n",
    "#    _ = plt.axvline(upper, c='r')\n",
    "#    lower = central_diffs.mean() - sigmas*central_diffs.std()\n",
    "#    _ = plt.axvline(lower, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5839c-bca3-42be-bb27-a07cfd4e6250",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#equal_temps = np.array([55, 110, 164.8, 220, 329.6, 440, 659.26, 880, 1318.5, 1760])\n",
    "#stretched = np.array([54.9 / 55, 109.8 / 110, 164.6 / 164.8, 220 / 220, 329.5 / 329.6, 440 / 440, 660.5 / 659.26, 881.9 / 880, 1324.8 / 1318.5 , 1772.5 / 1760])\n",
    "#def stretch_fit(x, c1, c2):\n",
    "#    return c1*np.exp(c2*x)\n",
    "#popt, pcov = optimize.curve_fit(stretch_fit, equal_temps, stretched, [0.1, 0.001])\n",
    "#_ = plt.plot(equal_temps, stretched)\n",
    "#_ = plt.plot(equal_temps, stretch_fit(equal_temps, popt[0], popt[1]))\n",
    "#plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc456a6-4fb2-4098-acbd-901e457e64c6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for cf in cluster_central_freqs:\n",
    "#    print(f'{cf}: {find_note(cluster_central_freqs[cf], notes_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457465e5-5277-4df9-864c-895cbf1b71d3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_to_3_dimensions(X, algo, params, show_title=None, xlab=None, ylab=None): # in progress\n",
    "    #font_size = 12\n",
    "    results = algo(**params).fit_transform(X)\n",
    "    #n_dim = results.shape[1] # TODO: account for number of dimensions, probably separate 2D and 3D functions\n",
    "    x_label = f'{algo.__name__}_1'\n",
    "    y_label = f'{algo.__name__}_2'\n",
    "    z_label = f'{algo.__name__}_3'\n",
    "    res_df = pd.DataFrame(results, columns=[x_label, y_label, z_label])\n",
    "    #splot = sns.scatterplot(data=res_df, x=x_label, y=y_label)\n",
    "    #if xlab:\n",
    "        #splot.set(xlabel=xlab)\n",
    "        #plt.xlabel(xlab, size=font_size)\n",
    "    #else:\n",
    "    #    splot.set(xlabel='')\n",
    "    #if ylab:\n",
    "    #    #splot.set(ylabel=ylab)\n",
    "    #    plt.ylabel(ylab, size=font_size)\n",
    "    #else:\n",
    "    #    splot.set(ylabel='')\n",
    "    #if show_title == 'auto':\n",
    "    #    title_elements = [f'{par[:min(6,len(par))]}:{str(val)[:min(6,len(par))]}' for par, val in params.items()]\n",
    "    #    title = ', '.join(title_elements)\n",
    "    #    _ = plt.title(title, size=font_size)\n",
    "    #elif show_title:\n",
    "    #    _ = plt.title(show_title, size=font_size)\n",
    "    #splot.tick_params(axis='both', which='both', left=False, right=False, bottom=False, top=False, labelbottom=False, labelleft=False)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe7865-ef0c-4798-b6c9-bcbfbf532b1b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def cluster_3D(df, algo, params): # in progress\n",
    "#    clusterer = algo(**params) # identify clusters in the UMAP results with DBSCAN\n",
    "#    clusters = clusterer.fit_predict(df)\n",
    "#    unique_clusters = np.unique(clusters)\n",
    "#    n_clusters = len(unique_clusters)\n",
    "#    color_dict = {uc:color for uc, color in zip(unique_clusters, palette[:n_clusters])}\n",
    "#    colors = [color_dict[cluster] for cluster in clusters]\n",
    "#    cols = df.columns.to_list()\n",
    "#    ipv.quickscatter(df[cols[0]], df[cols[1]], df[cols[2]], \n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.add_subplot(111, projection='3d')\n",
    "    #ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "    #fig.add_axes(ax)\n",
    "    #sc = ax.scatter(df[cols[0]], df[cols[1]], df[cols[2]], c=colors, s=100)\n",
    "    #plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.2, 1), loc=2)\n",
    "#    clustered_df = df.copy()\n",
    "#    clustered_df['cluster'] = clusters\n",
    "#    return clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269f0fb-7cd2-4798-ba30-e5525479aa9a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#umap_3D_df = reduce_to_3_dimensions(ft, UMAP, {'n_components':3, 'n_neighbors':5, 'min_dist':0.005, 'metric':'correlation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a341c5f-3c21-4438-9610-e324e2c53643",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#umap_dbscan_3D_df = cluster_3D(umap_3D_df, DBSCAN, {'eps':0.6, 'min_samples':7})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8521dfc3-9f25-44eb-a877-f36994cd869e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## FFT: PCA, t-SNE, UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ac7e6-e9ec-4ef3-85bc-886b99a78590",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Functions for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d95a20-ec7a-4883-b773-15a41ec734a8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Getting ffts of 0.5 second samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4aca1d-215d-4a3f-8d39-2828d7897478",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fts = np.array([])\n",
    "ins = []\n",
    "indices = []\n",
    "begins = []\n",
    "ends = []\n",
    "for index, row in equal_df.iterrows(): # for each file, cut into pieces, and apply fft\n",
    "    sr, amp = wavfile.read(row['file_path'])\n",
    "    amp = amp / max(abs(amp))\n",
    "    duration = len(amp) // sr\n",
    "    instrument = row['instrument']\n",
    "    begin = list(range(sr*2, sr*min(duration, 22), sr // 2)) # don't take more than 20 seconds of any file, start a couple seconds in, 0.5-sec samples\n",
    "    end = [i + sr for i in begin]\n",
    "    for j, k in zip(begin, end):\n",
    "        ft = abs(fft.fft(amp[j:k]))[:5000]\n",
    "        fts = np.append(fts, ft)\n",
    "        ins.append(instrument)\n",
    "        indices.append(index)\n",
    "    begins.append(begin)\n",
    "    ends.append(end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa9e64-edd3-4614-8d13-24cc7699e9b7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Formatting outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dce78d-ec75-467e-83ae-d7b01b5a2d94",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_fts = fts.shape[0]//len(ft)\n",
    "fts_shaped = fts.reshape((n_fts,len(ft)))\n",
    "print(fts_shaped.shape)\n",
    "subsamples_df = pd.DataFrame()\n",
    "subsamples_df['instrument'] = ins\n",
    "subsamples_df['equal_df_index'] = indices\n",
    "subsamples_df['i_begin'] = [i for sublist in begins for i in sublist]\n",
    "subsamples_df['i_end'] = [i for sublist in ends for i in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d775634-9e9e-43d9-bdd3-2aa96036dd6c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Filtering empty samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c24ba-513c-4073-a965-c1faae9fab57",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "empties = np.where(fts_shaped.mean(axis=1) == 0)[0]\n",
    "fts_nz = np.delete(fts_shaped, empties, axis=0)\n",
    "subsamples_nz_df = subsamples_df.drop(index=empties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4be44-13db-4153-9655-1bf6801f2cbc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Normalizing ffts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc18de0-4983-4664-bbdc-33cadde765de",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fts_normalized = fts_nz / fts_nz.mean(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5edc43-1bff-431c-9881-d87b088ae343",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426454d-0472-4179-9fa5-3cc467eb62ba",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "pca = PCA(n_components=2)\n",
    "pca_xy = pca.fit_transform(fts_normalized)\n",
    "pca_df = pd.DataFrame(pca_xy, columns=['pc1', 'pc2'])\n",
    "pca_df['instrument'] = subsamples_nz_df['instrument']\n",
    "splot = sns.scatterplot(data=pca_df, x='pc1', y='pc2', hue='instrument')\n",
    "splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c625900-dd93-4b0a-830a-5ab028d49974",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "There is some structure, but the separation is not great."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e651b8-c394-4d2a-8f10-5e94519478a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e62ee-ae15-47d9-8bb4-4dc28a4ba029",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10,7))\n",
    "tsne = TSNE(n_components=2, perplexity=15, n_iter=500)\n",
    "tsne_res = tsne.fit_transform(fts_normalized)\n",
    "tsne_res_df = pd.DataFrame(tsne_res, columns=['tsne1', 'tsne2'])\n",
    "tsne_res_df['instrument'] = subsamples_nz_df['instrument']\n",
    "splot = sns.scatterplot(data=tsne_res_df, x='tsne1', y='tsne2', hue='instrument')\n",
    "_ = splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39e4b7-2d2f-440c-a8a9-89e946bcf281",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "The separation is better with t-SNE, but still messy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac841b05-bb28-47b9-b695-c48a151a94d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aabb1e-a30c-4a2f-b476-6e3e65856c2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10,7))\n",
    "umap_results = UMAP(n_neighbors=15, min_dist=0.9, metric='correlation').fit_transform(fts_normalized)\n",
    "umap_df = pd.DataFrame(umap_results, columns=['umap1', 'umap2'])\n",
    "umap_df['instrument'] = subsamples_nz_df['instrument']\n",
    "_ = plt.figure(figsize=(10,7))\n",
    "splot = sns.scatterplot(data=umap_df, x='umap1', y='umap2', hue='instrument', palette=sns.color_palette(palette, 14))\n",
    "_ = splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad9379-6d04-43fa-8226-f1da56a82d0e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameter_grid(fts_normalized, UMAP, {'n_neighbors':[5,15,45], 'min_dist':[0.1, 0.3, 0.9], 'metric':'correlation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582fb2b-7d24-4007-97b3-08f82a6a91be",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameter_grid(fts_normalized, UMAP, {'n_neighbors':[9,12,15], 'min_dist':[0.2, 0.5, 0.8], 'metric':'correlation'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be4d12-b5de-42e9-a58f-41568cff4604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## STFT: t-SNE and UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a3364-2e04-4de1-a84a-966faa796053",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins = []\n",
    "stfts = np.array([])\n",
    "for index, row in equal_df.iterrows(): # for each file, cut into pieces, and apply stft\n",
    "    sr, amp = wavfile.read(row['file_path'])\n",
    "    amp = amp / max(abs(amp)) # normalize the amplitude, cast to float\n",
    "    ft = np.abs(lb.stft(y=amp[sr*7:sr*12], n_fft=8192))\n",
    "    n_rows = ft.shape[1]\n",
    "    stfts = np.append(stfts, ft)\n",
    "    ins += [row['instrument']]*n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f98866c-c0ff-413a-8989-44af2a0288fa",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ld.specshow(lb.amplitude_to_db(ft[:,0:10], ref=np.max), y_axis='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d27a6-26f0-4a52-bf42-fb096c18ff72",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stfts_shaped = stfts.reshape((stfts.shape[0] // ft.shape[0], ft.shape[0]))\n",
    "stfts_shaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ea26c-d676-4a09-baaa-13820748a12c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ld.specshow(lb.amplitude_to_db(stfts_shaped[:,0:208], ref=np.max), y_axis='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf7df5-9f23-4005-84ff-cec54c54d238",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=500)\n",
    "tsne_res = tsne.fit_transform(stfts_shaped)\n",
    "tsne_res_df = pd.DataFrame(tsne_res, columns=['tsne1', 'tsne2'])\n",
    "tsne_res_df['instrument'] = ins\n",
    "splot = sns.scatterplot(data=tsne_res_df, x='tsne1', y='tsne2', hue='instrument', palette=sns.color_palette(palette, 14))\n",
    "splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edeaf5-5132-4ded-8c5a-552daafd0651",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameter_grid(stfts_shaped, TSNE, {'perplexity':[5, 20, 50], 'n_iter':[500]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fd858",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "umap_results = UMAP(n_neighbors=7, min_dist=0.1, metric='correlation').fit_transform(stfts_shaped)\n",
    "umap_df = pd.DataFrame(umap_results, columns=['umap1', 'umap2'])\n",
    "umap_df['instrument'] = ins\n",
    "plt.figure(figsize=(10,7))\n",
    "splot = sns.scatterplot(data=umap_df, x='umap1', y='umap2', hue='instrument', palette=sns.color_palette(palette, 14))\n",
    "splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be3178-f473-4534-9e64-6cd9f0120fe2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## MFCC: t-SNE and UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85798d77-3b59-4272-aa60-eed6c5c4c0e5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mfccs = np.array([])\n",
    "ins = []\n",
    "for index, row in equal_df.iterrows(): # for each file, cut into pieces, and apply mfcc\n",
    "    sr, amp = wavfile.read(row['file_path'])\n",
    "    amp = amp / max(abs(amp)) # normalize the amplitude, cast to float\n",
    "    duration = len(amp) // sr\n",
    "    mfcc = lb.feature.mfcc(y=amp[sr*7:sr*12], sr=sr, n_mfcc=40)\n",
    "    n_rows = mfcc.shape[1]\n",
    "    mfccs = np.append(mfccs, mfcc)\n",
    "    ins += [row['instrument']]*n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be381548-3a43-4325-8f5d-726381183585",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mfccs_shaped = mfccs.reshape((mfccs.shape[0]//40, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e773d8a-5ada-49bd-bbbb-20cc7dc153cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16615a37-bc1c-4bf6-bf87-2b9e095d553a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "tsne = TSNE(n_components=2, perplexity=25, n_iter=500)\n",
    "tsne_res = tsne.fit_transform(mfccs_shaped)\n",
    "tsne_res_df = pd.DataFrame(tsne_res, columns=['tsne1', 'tsne2'])\n",
    "tsne_res_df['instrument'] = instruments\n",
    "splot = sns.scatterplot(data=tsne_res_df, x='tsne1', y='tsne2', hue='instrument')\n",
    "splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad3473-7590-4f18-99f7-f15bc307a005",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Using MFCCs doesn't seem to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c8915-7c70-423e-bafb-dc6efaea1109",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "umap_results = UMAP(n_neighbors=5, min_dist=0.001, metric='correlation').fit_transform(mfccs_shaped)\n",
    "umap_df = pd.DataFrame(umap_results, columns=['umap1', 'umap2'])\n",
    "umap_df['instrument'] = ins\n",
    "plt.figure(figsize=(10,7))\n",
    "splot = sns.scatterplot(data=umap_df, x='umap1', y='umap2', hue='instrument', palette=sns.color_palette(palette, 14))\n",
    "splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37c9be-8e5b-4d2e-b96e-88b99552b7df",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lb.display.specshow(mfccs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b451c05-7a82-40bd-a8bc-992bc14c2694",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## MusicNet Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72b0d7-61c6-4197-858c-296be4de5dfe",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fts = np.array([])\n",
    "ins = []\n",
    "for i in cfpv_df['id']: # for each file, cut into pieces, apply fft, and filter\n",
    "    sr, amp = wavfile.read(f'musicnet/{i}.wav')\n",
    "    instrument = cfpv_df[cfpv_df['id'] == i]['instrument']\n",
    "    for j in range(0, sr*100, sr):\n",
    "        ft = abs(fft.fft(amp[j:j+sr]))[:5000]\n",
    "        fts = np.append(fts, ft)\n",
    "        ins.append(instrument)\n",
    "print(fts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e964ab-3c24-4ce5-be02-0fcd8ab3347f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_fts = fts.shape[0]//len(ft)\n",
    "fts_shaped = fts.reshape((n_fts,len(ft)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e61ec-eaad-4715-828b-62811a3ffe4e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_xy = pca.fit_transform(fts_shaped)\n",
    "pca_df = pd.DataFrame(pca_xy, columns=['pc1', 'pc2'])\n",
    "sns.scatterplot(data=pca_df, x='pc1', y='pc2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ca7fa-3e22-4f2a-b117-1544d259b5e3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "There is some structure, but no clear groups.\n",
    "I should check for empty rows and normalize first though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef9e10-221f-4881-be59-646767522c47",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonzero_fts = np.nonzero(fts_shaped.sum(axis=1))[0]\n",
    "nz_fts = fts_shaped[nonzero_fts]\n",
    "fts_normalized = nz_fts / nz_fts.sum(axis=1, keepdims=True)\n",
    "ins_normalized = np.array(ins)[nonzero_fts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877f1c0-8512-46d1-9f52-6c1fac23280f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_xy = pca.fit_transform(fts_normalized)\n",
    "pca_df = pd.DataFrame(pca_xy, columns=['pc1', 'pc2'])\n",
    "pca_df['instrument'] = ins_normalized\n",
    "sns.scatterplot(data=pca_df, x='pc1', y='pc2', hue='instrument')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93455013-81a2-4c97-a677-93feeef40fd4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Even looking at nothing but the Fourier transform, pca tends to group instrument samples near each other. This will need to verified with a more diverse data set though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfef748-9611-44c5-8962-b4805947e1b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=25, n_iter=500)\n",
    "tsne_res = tsne.fit_transform(fts_normalized)\n",
    "tsne_res_df = pd.DataFrame(tsne_res, columns=['tsne1', 'tsne2'])\n",
    "tsne_res_df['instrument'] = ins_normalized\n",
    "sns.scatterplot(data=tsne_res_df, x='tsne1', y='tsne2', hue='instrument')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541150c-4946-425e-b4a3-90182e20c9d8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "t-SNE generates cleaner separations between groups than pca, as expected. Some groups are split into subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc5dd1-611b-4cd2-a052-b1cf5cdb8d0c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "umap_results = UMAP(n_neighbors=7, min_dist=0.05, metric='correlation').fit_transform(fts_normalized)\n",
    "umap_df = pd.DataFrame(umap_results, columns=['umap1', 'umap2'])\n",
    "umap_df['instrument'] = ins_normalized\n",
    "plt.figure(figsize=(10,7))\n",
    "#dbscan = DBSCAN(eps=0.45, min_samples=9)\n",
    "#umap_clusters = dbscan.fit_predict(umap_df)\n",
    "splot = sns.scatterplot(data=umap_df, x='umap1', y='umap2', hue='instrument')\n",
    "splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a6ba1-8cea-4b6e-aecc-1334d1e73e27",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "As usual, UMAP creates the most clearly-separated groups, but there are more of them than I expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35cab1-a1a8-4fbe-a0a0-bf3b337ea6a2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "I will use UMAP over PCA or t-SNE because of this ability to clearly separate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64768a1e-5458-4b44-b5b4-cf1ef20e464d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Let's find out what characterizes each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5ab8c-09aa-4a0a-9165-ce72249d48a4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "dbscan = DBSCAN(eps=0.9, min_samples=7)\n",
    "umap_clusters = dbscan.fit_predict(umap_df[['umap1','umap2']])\n",
    "splot = sns.scatterplot(data=umap_df, x='umap1', y='umap2', hue=umap_clusters.astype(str))\n",
    "splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bac6bc-a671-4f11-a75d-fb875122a1cc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "group0 = fts_normalized[np.where(umap_clusters == 0)[0]]\n",
    "plt.plot(group0[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227036b-d5c0-4d06-a9ec-0be5a09609b0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trim_zeros(amplitude):\n",
    "    nonzeros = np.nonzero(amplitude)[0]\n",
    "    zero_spans = nonzeros[1:] - nonzeros[:-1]\n",
    "    adj_nonzeros = np.where(zero_spans == 1, np.arange())[0]\n",
    "    i_adj_begin = adj_nonzeros[0]\n",
    "    i_adj_end = adj_nonzeros[-1]\n",
    "    i_begin = zero_spans[i_adj_begin]\n",
    "    i_end = zero_spans[i_adj_end]\n",
    "    i_start = nonzeros[0]\n",
    "    i_end = nonzeros[-1]\n",
    "    subsample = amplitude[i_start:i_end+1]\n",
    "    #print(f'i_start: {i_start}, i_end:{i_end-len(amplitude)+1}')\n",
    "    return amplitude[i_start:i_end+1]\n",
    "\n",
    "fts = np.array([])\n",
    "for i in cfpv_df['id']: # for each file, cut into pieces, then filter the pieces.\n",
    "    sr, amp = wavfile.read(f'musicnet/{i}.wav')\n",
    "    samp = trim_zeros(amp)\n",
    "    print(samp)\n",
    "    #for j in range(100):\n",
    "    #    samp[j:j+sr]\n",
    "    #samp = trim_intro(amp, sr)[0:sr]\n",
    "    #ft = np.abs(fft.fft(samp))[0:4000]\n",
    "    #fts = np.append(fts, ft)\n",
    "#print(fts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b22b5-4830-4ceb-a421-bd081ba17c51",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sr1, data1 = wavfile.read('musicnet/2298.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349defc9-4929-4a47-a599-0b06ba5ddb42",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def real_start(amp_data, sr): # do a fft on 1-sec intervals in 0.1 sec steps until the peak of the fft occurs at > 101 Hz \n",
    "    i = np.nonzero(amp_data)[0][0]\n",
    "    while i < len(amp_data):\n",
    "        ft = np.abs(fft.fft(amp_data[i:i+sr]))\n",
    "        ft_max = ft.max()\n",
    "        peaks, peak_dict = signal.find_peaks(ft[0:4000], height=ft_max/10)\n",
    "        heights = peak_dict['peak_heights']\n",
    "        if len(heights) < 2:\n",
    "            print(peaks)\n",
    "            print(heights)\n",
    "            plt.figure(figsize=(16,6))\n",
    "            plt.supblot(1, 2, 1)\n",
    "            plt.plot(amp_data[i:i+sr])\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(ft[0:4000])\n",
    "        i_max = heights.argmax() # index of max frequency\n",
    "        f_max = peaks[i_max]\n",
    "        if f_max in [99, 100, 101] or f_max in [49, 50, 51]:\n",
    "            i += sr//10\n",
    "        else:\n",
    "            return i + 3 * sr // 4\n",
    "    return 0\n",
    "\n",
    "def trim_intro(amp_data, sample_rate):\n",
    "    i_start = real_start(amp_data, sample_rate)\n",
    "    return amp_data[i_start:]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sample1 = trim_intro(data1, sr1)[0:sr1]\n",
    "plt.plot(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5371cd1-e926-4f42-8fab-55afe04893b9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ft1733 = fft.fft(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eda198-6296-49e7-afe6-404f66216893",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rolling_mean(x, w=501):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "ft_limit = 4000\n",
    "plt.figure(figsize=(18,9))\n",
    "ft_abs = np.abs(ft1733)[0:ft_limit]\n",
    "plt.plot(ft_abs)\n",
    "#ft_mean = ft_abs.mean()\n",
    "rmean_width = ft_limit//8 +1\n",
    "rmean = rolling_mean(ft_abs, w=rmean_width)\n",
    "pad = np.ones(rmean_width//2)\n",
    "rmean = 1.5*np.append(np.insert(rmean, 0, pad*rmean[0]), pad*rmean[-1])\n",
    "ft_max = ft_abs.max()\n",
    "peaks, _ = signal.find_peaks(ft_abs, height=rmean, distance=25, prominence=ft_max/100, wlen=21)\n",
    "plt.plot(peaks, ft_abs[peaks], 'rx')\n",
    "plt.plot(rmean, 'g')\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75249f2e-f817-44a9-a5e8-7a0a5115379b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dominant_freq(ft):\n",
    "    aft = np.abs(ft)[:5000]\n",
    "    ft_max = max(aft)\n",
    "    pks, _ = signal.find_peaks(aft, distance=25, prominence=ft_max/100, wlen=21)\n",
    "    i_peak_max = aft[pks].argmax()\n",
    "    return pks[i_peak_max]\n",
    "dominant_freq(ft1733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7560c-3516-4d2f-95cf-ee2183467c71",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fts = np.array([])\n",
    "for i in mn_instruments_df['id']:\n",
    "    sr, amp = wavfile.read(f'musicnet/{i}.wav')\n",
    "    samp = trim_intro(amp, sr)[0:sr]\n",
    "    ft = np.abs(fft.fft(samp))[0:4000]\n",
    "    fts = np.append(fts, ft)\n",
    "print(fts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59287e69-0baf-4a03-ab61-1f87b1a93203",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ftsize = fts.shape[0]//len(ft)\n",
    "fts = fts.reshape((ftsize,len(ft)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f5ddc-586c-4cc1-a7ff-94fcf7833d39",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampsize = samps.shape[0]//len(samp)\n",
    "samps = samps.reshape((sampsize,len(samp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a7f5c-56e1-4d64-ba17-d95c1fea16c7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "I can't use StandardScaler here. I chose to normalize each signal by dividing by its mean absolute amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e589a5-c336-4e99-8a74-726e39704e98",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#norm_samps = samps / abs(samps).mean(axis=0, keepdims=True)\n",
    "norm_samps = samps / 215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c4a47-67f7-48cd-ac18-39afd6714d66",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mn_instruments_df = pd.concat([mn_instruments_df, pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca8976-05d7-4ade-9401-17d7e219be35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Scaled FFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d4e05-a2c9-4198-93d0-3d44ee736b1d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normal(x, mu, sigma):\n",
    "    return np.exp(-0.5*((x-mu)/sigma)**2)/(sigma*math.sqrt(2*math.pi))\n",
    "\n",
    "def bounded_normal(x, mu, sigma):\n",
    "    y = normal(x, mu, sigma)\n",
    "    return y/sum(y)\n",
    "\n",
    "def bounded_normal_convolution(aft, freq, sigma):\n",
    "    running_bounded_normal_mean = []\n",
    "    for i in freq:\n",
    "        bn = bounded_normal(freq, i, sigma)\n",
    "        running_bounded_normal_mean.append(np.dot(bn, aft))\n",
    "    return np.array(running_bounded_normal_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a249b9-45b9-4da3-844d-e92088fe9252",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_freqs = len(freq)\n",
    "bounded_normal_array = np.zeros((n_freqs, n_freqs))\n",
    "for i in range(n_freqs):\n",
    "    bounded_normal_array[i,:] = bounded_normal(freq, i, len(freq) // 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa54609-a378-4919-ad07-1466bf38365e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bncs = np.zeros((n_freqs,))\n",
    "for i in freq:\n",
    "    bncs[i] = np.dot(bounded_normal_array[i,:], aft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c507ff-cfe2-47c3-a83c-0bf2dcef8f59",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "i = 0\n",
    "plt.plot(freq, ft_abs_array[i])\n",
    "bncs = []\n",
    "bnc = bounded_normal_convolution(ft_abs_array[i], freq, freq[-1]//10)\n",
    "bncs.append(bnc)\n",
    "plt.plot(freq, bncs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f478c0b-32c5-4251-9a15-9817bca4524c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ft_abs_shaped = ft_abs_array.reshape((len(ft_abs_array) // len(ft_abs), len(ft_abs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0eb89-baee-41e5-8440-39e23ab3d702",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fts = np.array([])\n",
    "ins = []\n",
    "for index, row in equal_df.iterrows(): # for each file, cut into pieces, and apply fft\n",
    "    sr, amp = wavfile.read(row['file_path'])\n",
    "    for j in range(0, sr*30, sr):\n",
    "        ft = abs(fft.fft(amp[j:j+sr]))[:5000]\n",
    "        fts = np.append(fts, ft)\n",
    "        ins.append(row['instrument'])\n",
    "print(fts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092ef68-b034-4e50-b726-f4107f1cc97d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_fts = fts.shape[0]//len(ft)\n",
    "fts_shaped = fts.reshape((n_fts,len(ft)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f72c68-5aa8-4e41-967d-1e859def205c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonzero_fts = np.nonzero(fts_shaped.sum(axis=1))[0]\n",
    "nz_fts = fts_shaped[nonzero_fts]\n",
    "fts_normalized = nz_fts / nz_fts.sum(axis=1, keepdims=True)\n",
    "#fts_normalized = nz_fts / nz_fts.max(axis=1, keepdims=True)\n",
    "ins_normalized = np.array(ins)[nonzero_fts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d11f1-f6a7-4890-a185-57a1a9675328",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "umap_results = UMAP(n_neighbors=18, min_dist=0.5, metric='correlation').fit_transform(fts_normalized)\n",
    "umap_df = pd.DataFrame(umap_results, columns=['umap1', 'umap2'])\n",
    "umap_df['instrument'] = ins_normalized\n",
    "plt.figure(figsize=(10,7))\n",
    "splot = sns.scatterplot(data=umap_df, x='umap1', y='umap2', hue='instrument', palette=sns.color_palette(palette, 14))\n",
    "splot.legend(bbox_to_anchor=(1.2, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
